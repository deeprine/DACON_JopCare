{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEaNnVP8Jn4i"
   },
   "source": [
    "# tabnet and catboost ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO5nbnCrJ3OA"
   },
   "source": [
    "## Colab 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCZrQmpsy_Fs"
   },
   "outputs": [],
   "source": [
    "# ================================================================================ #\n",
    "# =========================== Goolge Colab File Upload =========================== #\n",
    "# ================================================================================ #\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 출력값 초기화\n",
    "from google.colab import output\n",
    "output.clear()\n",
    "\n",
    "# 경로 수정\n",
    "import os\n",
    "os.chdir(\"drive/MyDrive/Colab Notebooks/잡케어 추천 알고리즘 경진 대회\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "!pip install pytorch-tabnet==3.1.1\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IvZt-OTKE_s"
   },
   "source": [
    "## Load Data from google Drive\n",
    "- train_csv : train.csv 파일을 참조한 pandas 데이터\n",
    "- test_csv : test.csv 파일을 참조한 pandas 데이터\n",
    "- sample_submission : sample_submission.csv 파일을 참조한 pandas 데이터\n",
    "- unknown1/2/3_csv : 추가 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCKpSIQ-zHGH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import glob2\n",
    "import json\n",
    "\n",
    "train_csv = pd.read_csv('./dataset2/train.csv') \n",
    "test_csv = pd.read_csv('./dataset2/test.csv')\n",
    "property_d_code = pd.read_csv('./dataset2/속성_D_코드.csv')\n",
    "property_l_code = pd.read_csv('./dataset2/속성_L_코드.csv')\n",
    "property_h_code = pd.read_csv('./dataset2/속성_H_코드.csv')\n",
    "sample_submission = pd.read_csv('./dataset2/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHzfdfZh7cCz"
   },
   "outputs": [],
   "source": [
    "df = train_csv.copy(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_csv 데이터프레임의 bool(True, False)형태의 데이터를 0과 1로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOp03Fn2Ao9F"
   },
   "outputs": [],
   "source": [
    "df['target'] = df['target'].apply(lambda x : int(x)).astype('int64')\n",
    "\n",
    "bool_cols = ['d_l_match_yn','d_m_match_yn','d_s_match_yn','h_l_match_yn','h_m_match_yn','h_s_match_yn']\n",
    "\n",
    "for bool_col in bool_cols:\n",
    "    df[bool_col] = df[bool_col].apply(lambda x : int(x)).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEgCVK8uLiwQ",
    "outputId": "b2ba4db4-0321-42ac-c7c8-de0afb881cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attribute_d_code', 'attribute_d_d', 'attribute_d_s', 'attribute_d_m',\n",
       "       'attribute_d_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_d_code.rename(columns = {\n",
    "    \"속성 D 코드\" : \"attribute_d_code\",\n",
    "    \"속성 D 세분류코드\":\"attribute_d_d\",\n",
    "    \"속성 D 소분류코드\":\"attribute_d_s\",\n",
    "    \"속성 D 중분류코드\":\"attribute_d_m\",\n",
    "    \"속성 D 대분류코드\":\"attribute_d_l\",\n",
    "}, inplace = True)\n",
    "property_d_code.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KtCE0-wLiyu",
    "outputId": "7f7a90a1-b86d-403c-bd1b-bfa9ed7ab947"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attribute_h_code', 'attribute_h_m', 'attribute_h_l'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_h_code.rename(columns = {\n",
    "    \"속성 H 코드\" : \"attribute_h_code\",\n",
    "    \"속성 H 중분류코드\" : \"attribute_h_m\",\n",
    "    \"속성 H 대분류코드\" : \"attribute_h_l\",   \n",
    "}, inplace = True)\n",
    "property_h_code.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnAgrsMzLi1Q",
    "outputId": "1c222b54-9cc8-4abf-aef5-3cd27048101f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attribute_l_code', 'attribute_l_d', 'attribute_l_s', 'attribute_l_m',\n",
       "       'attribute_l_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_l_code.rename(columns = {\n",
    "    \"속성 L 코드\" : \"attribute_l_code\",\n",
    "    \"속성 L 세분류코드\":\"attribute_l_d\",\n",
    "    \"속성 L 소분류코드\":\"attribute_l_s\",\n",
    "    \"속성 L 중분류코드\":\"attribute_l_m\",\n",
    "    \"속성 L 대분류코드\":\"attribute_l_l\",\n",
    "}, inplace = True)\n",
    "property_l_code.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHYeQsheCk53"
   },
   "outputs": [],
   "source": [
    "code_d = property_d_code.copy(...)\n",
    "code_h = property_h_code.copy(...)\n",
    "code_l = property_l_code.copy(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCziUDrEBFgP"
   },
   "outputs": [],
   "source": [
    "def merge_dataframe(df, df_added, col):\n",
    "    df_copy = df.copy(...)\n",
    "    df_added_copy = df_added.copy(...)\n",
    "    \n",
    "    df_added_copy = df_added_copy.add_prefix(f\"{col}_\")\n",
    "    df_added_copy.columns.values[0] = col\n",
    "\n",
    "    return pd.merge(df_copy, df_added_copy, how = 'left', on = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Eg6tAnHRRCI"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df_origin, cols_merge, cols_equi, cols_drop):\n",
    "    df = df_origin.copy(...)\n",
    "\n",
    "    # merge data\n",
    "    for col, df_code in cols_merge:\n",
    "        df = merge_dataframe(df, df_code, col)\n",
    "\n",
    "    # boolean type convert to int type\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n",
    "\n",
    "    df = df.drop(columns=cols_drop)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 똑같은 행이 대다수인 column들이 존재함, 변별력이 없다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdcp2nVfVNWH",
    "outputId": "786563c6-a5c2-4048-85c3-b455c26bdfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col :person_prefer_f detected\n",
      "col :person_prefer_g detected\n",
      "['person_prefer_f', 'person_prefer_g', 'id', 'contents_open_dt', 'person_rn', 'contents_rn']\n"
     ]
    }
   ],
   "source": [
    "# 변별력이 없는 column 추가\n",
    "cols_drop = []\n",
    "columns = df.columns.tolist()\n",
    "for col in columns:\n",
    "    if len(np.unique(df[col].values)) == 1:\n",
    "        print(\"col :{} detected\".format(col))\n",
    "        cols_drop.append(col)\n",
    "\n",
    "# 그 외 columns 중 범주형 변수가 아닌 요소 제외\n",
    "cols_drop.extend(['id', 'contents_open_dt','person_rn','contents_rn'])\n",
    "print(cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNFz5mWDCZSI"
   },
   "outputs": [],
   "source": [
    "cols_merge = [\n",
    "              (\"person_prefer_d_1\" , code_d),\n",
    "              (\"person_prefer_d_2\" , code_d),\n",
    "              (\"person_prefer_d_3\" , code_d),\n",
    "              (\"contents_attribute_d\" , code_d),\n",
    "              (\"person_prefer_h_1\" , code_h),\n",
    "              (\"person_prefer_h_2\" , code_h),\n",
    "              (\"person_prefer_h_3\" , code_h),\n",
    "              (\"contents_attribute_h\" , code_h),\n",
    "              (\"contents_attribute_l\" , code_l),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXk6WOCd4wO2"
   },
   "outputs": [],
   "source": [
    "cols_equi = [\n",
    "    (\"contents_attribute_c\",\"person_prefer_c\"),\n",
    "    (\"contents_attribute_e\",\"person_prefer_e\"),\n",
    "    (\"person_prefer_d_2_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_2_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_2_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
    "    (\"person_prefer_d_3_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_3_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_3_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
    "    (\"person_prefer_h_1_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_2_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_3_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_1_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
    "    (\"person_prefer_h_2_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
    "    (\"person_prefer_h_3_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코드D,L,H 그리고 train 데이터를 하나의 데이터프레임으로 합치며, bool형태의 데이터는 0과 1로 변경하도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85naXx4N5UQ4"
   },
   "outputs": [],
   "source": [
    "df_preprocessed = preprocess_data(df, cols_merge, cols_equi, cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlDaJbTZl-o-"
   },
   "outputs": [],
   "source": [
    "output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCcRbw5n3wf5",
    "outputId": "b2973d83-d8c6-4594-e9d5-d02a2a6fba42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of categorical feature : 47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model  import TabNetClassifier \n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "x_cols = df_preprocessed.columns.drop(['target']).tolist()\n",
    "y_cols = ['target']\n",
    "\n",
    "categorical_feature = df_preprocessed[x_cols].columns[df_preprocessed[x_cols].nunique() > 2].to_list()\n",
    "print(\"num of categorical feature : {}\".format(len(categorical_feature)))\n",
    "df_train, df_test = train_test_split(df_preprocessed, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2nvBl0jeO81",
    "outputId": "1165b7b6-87e2-4823-896b-99fb165735cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f516a36ad90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-test split\n",
    "x_train, y_train = df_train[x_cols], df_train[y_cols]\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.2)\n",
    "x_test, y_test = df_test[x_cols], df_test[y_cols]\n",
    "\n",
    "# catboost\n",
    "cbc = CatBoostClassifier(\n",
    "    random_seed = 42,\n",
    "    task_type = 'GPU',\n",
    "    devices = '0:1',\n",
    "    custom_metric = ['Logloss','F1'],\n",
    ")\n",
    "\n",
    "d_train = Pool(x_train, y_train, feature_names = list(x_train.columns), cat_features = categorical_feature)\n",
    "d_valid = Pool(x_valid, y_valid, feature_names = list(x_valid.columns), cat_features = categorical_feature)\n",
    "d_test = Pool(x_test, y_test, feature_names = list(x_test.columns), cat_features = categorical_feature)\n",
    "\n",
    "cbc.fit(d_train, eval_set = d_valid, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabNet Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WeTpYrubegLy",
    "outputId": "4add772c-d525-43fc-e975-30658ecb8f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 2.29694 | val_0_unsup_loss: 1.08377 |  0:00:23s\n",
      "epoch 1  | loss: 1.05434 | val_0_unsup_loss: 1.02138 |  0:00:45s\n",
      "epoch 2  | loss: 1.01407 | val_0_unsup_loss: 1.00589 |  0:01:06s\n",
      "epoch 3  | loss: 1.00472 | val_0_unsup_loss: 0.99978 |  0:01:30s\n",
      "epoch 4  | loss: 1.00107 | val_0_unsup_loss: 0.99481 |  0:01:52s\n",
      "epoch 5  | loss: 0.9982  | val_0_unsup_loss: 0.98696 |  0:02:16s\n",
      "epoch 6  | loss: 0.99302 | val_0_unsup_loss: 0.97394 |  0:02:37s\n",
      "epoch 7  | loss: 0.98749 | val_0_unsup_loss: 0.96401 |  0:03:00s\n",
      "epoch 8  | loss: 0.98268 | val_0_unsup_loss: 0.95475 |  0:03:21s\n",
      "epoch 9  | loss: 0.97784 | val_0_unsup_loss: 0.94371 |  0:03:43s\n",
      "epoch 10 | loss: 0.97034 | val_0_unsup_loss: 0.92704 |  0:04:04s\n",
      "epoch 11 | loss: 0.96001 | val_0_unsup_loss: 0.90568 |  0:04:25s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.90568\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py:97: UserWarning: Pretraining: cat_emb_dim changed from 3 to 1\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from unsupervised pretraining\n",
      "epoch 0  | loss: 0.68786 | train_logloss: 0.67798 | train_f1: 0.59103 | val_logloss: 0.67813 | val_f1: 0.59125 |  0:00:20s\n",
      "epoch 1  | loss: 0.67868 | train_logloss: 0.67465 | train_f1: 0.60835 | val_logloss: 0.67548 | val_f1: 0.60665 |  0:00:41s\n",
      "epoch 2  | loss: 0.67564 | train_logloss: 0.67154 | train_f1: 0.60661 | val_logloss: 0.67281 | val_f1: 0.60461 |  0:01:02s\n",
      "epoch 3  | loss: 0.673   | train_logloss: 0.6693  | train_f1: 0.62005 | val_logloss: 0.67096 | val_f1: 0.61677 |  0:01:22s\n",
      "epoch 4  | loss: 0.67092 | train_logloss: 0.66749 | train_f1: 0.61664 | val_logloss: 0.66946 | val_f1: 0.61314 |  0:01:43s\n",
      "epoch 5  | loss: 0.66947 | train_logloss: 0.66596 | train_f1: 0.61509 | val_logloss: 0.66812 | val_f1: 0.61102 |  0:02:04s\n",
      "epoch 6  | loss: 0.668   | train_logloss: 0.66465 | train_f1: 0.61817 | val_logloss: 0.66683 | val_f1: 0.61475 |  0:02:25s\n",
      "epoch 7  | loss: 0.66668 | train_logloss: 0.6633  | train_f1: 0.62418 | val_logloss: 0.66612 | val_f1: 0.61883 |  0:02:46s\n",
      "epoch 8  | loss: 0.66551 | train_logloss: 0.66198 | train_f1: 0.62144 | val_logloss: 0.66488 | val_f1: 0.61507 |  0:03:07s\n",
      "epoch 9  | loss: 0.66418 | train_logloss: 0.66082 | train_f1: 0.62513 | val_logloss: 0.66454 | val_f1: 0.61751 |  0:03:28s\n",
      "epoch 10 | loss: 0.66283 | train_logloss: 0.6596  | train_f1: 0.62879 | val_logloss: 0.6636  | val_f1: 0.621   |  0:03:49s\n",
      "epoch 11 | loss: 0.66178 | train_logloss: 0.65797 | train_f1: 0.62652 | val_logloss: 0.66223 | val_f1: 0.61779 |  0:04:10s\n",
      "epoch 12 | loss: 0.66051 | train_logloss: 0.6569  | train_f1: 0.62855 | val_logloss: 0.66156 | val_f1: 0.62076 |  0:04:31s\n",
      "epoch 13 | loss: 0.65961 | train_logloss: 0.65581 | train_f1: 0.63189 | val_logloss: 0.66066 | val_f1: 0.62338 |  0:04:52s\n",
      "epoch 14 | loss: 0.65848 | train_logloss: 0.6547  | train_f1: 0.62769 | val_logloss: 0.66007 | val_f1: 0.61927 |  0:05:12s\n",
      "epoch 15 | loss: 0.65763 | train_logloss: 0.65391 | train_f1: 0.63197 | val_logloss: 0.65953 | val_f1: 0.62315 |  0:05:33s\n",
      "epoch 16 | loss: 0.65665 | train_logloss: 0.65292 | train_f1: 0.63112 | val_logloss: 0.65894 | val_f1: 0.62187 |  0:05:54s\n",
      "epoch 17 | loss: 0.65593 | train_logloss: 0.65237 | train_f1: 0.63326 | val_logloss: 0.65913 | val_f1: 0.62249 |  0:06:14s\n",
      "epoch 18 | loss: 0.65523 | train_logloss: 0.6515  | train_f1: 0.63978 | val_logloss: 0.65877 | val_f1: 0.62971 |  0:06:34s\n",
      "epoch 19 | loss: 0.65438 | train_logloss: 0.65072 | train_f1: 0.63955 | val_logloss: 0.65812 | val_f1: 0.62891 |  0:06:54s\n",
      "epoch 20 | loss: 0.65379 | train_logloss: 0.64983 | train_f1: 0.63047 | val_logloss: 0.65784 | val_f1: 0.61878 |  0:07:14s\n",
      "epoch 21 | loss: 0.65318 | train_logloss: 0.64933 | train_f1: 0.62624 | val_logloss: 0.65833 | val_f1: 0.61415 |  0:07:34s\n",
      "epoch 22 | loss: 0.65235 | train_logloss: 0.64864 | train_f1: 0.63881 | val_logloss: 0.65722 | val_f1: 0.62665 |  0:07:55s\n",
      "epoch 23 | loss: 0.65192 | train_logloss: 0.648   | train_f1: 0.63926 | val_logloss: 0.65715 | val_f1: 0.62801 |  0:08:14s\n",
      "epoch 24 | loss: 0.65136 | train_logloss: 0.64717 | train_f1: 0.64417 | val_logloss: 0.65728 | val_f1: 0.63143 |  0:08:34s\n",
      "epoch 25 | loss: 0.65083 | train_logloss: 0.64684 | train_f1: 0.64299 | val_logloss: 0.65673 | val_f1: 0.62974 |  0:08:54s\n",
      "epoch 26 | loss: 0.65022 | train_logloss: 0.64574 | train_f1: 0.64319 | val_logloss: 0.65681 | val_f1: 0.62932 |  0:09:14s\n",
      "epoch 27 | loss: 0.64984 | train_logloss: 0.64548 | train_f1: 0.63374 | val_logloss: 0.65649 | val_f1: 0.6187  |  0:09:34s\n",
      "epoch 28 | loss: 0.64918 | train_logloss: 0.64459 | train_f1: 0.64429 | val_logloss: 0.65654 | val_f1: 0.62922 |  0:09:54s\n",
      "epoch 29 | loss: 0.6484  | train_logloss: 0.64418 | train_f1: 0.64357 | val_logloss: 0.65644 | val_f1: 0.62659 |  0:10:14s\n",
      "epoch 30 | loss: 0.64814 | train_logloss: 0.6436  | train_f1: 0.63777 | val_logloss: 0.65694 | val_f1: 0.6192  |  0:10:34s\n",
      "epoch 31 | loss: 0.64749 | train_logloss: 0.64325 | train_f1: 0.64248 | val_logloss: 0.65615 | val_f1: 0.6248  |  0:10:54s\n",
      "epoch 32 | loss: 0.64683 | train_logloss: 0.64267 | train_f1: 0.64678 | val_logloss: 0.6565  | val_f1: 0.62988 |  0:11:14s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 24 and best_val_f1 = 0.63143\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "x_train_tab = x_train.copy(...)\n",
    "x_valid_tab = x_valid.copy(...)\n",
    "x_test_tab = x_test.copy(...)\n",
    "\n",
    "# preprocessing for TabNet\n",
    "cat_idxs = []\n",
    "cat_dims = []\n",
    "for idx, col in enumerate(x_train_tab.columns):\n",
    "    if 'match' not in col and col!='target': # match -> boolean의 경우, 굳이 label encoder를 거칠 필요가 없다\n",
    "        le = LabelEncoder()\n",
    "        le.fit(x_train_tab[col].values)\n",
    "        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        x_train_tab[col] = x_train_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        x_valid_tab[col] = x_valid_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        x_test_tab[col] = x_test_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        cat_idxs.append(idx)\n",
    "        cat_dims.append(len(le_dict)+1)\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    optimizer_fn=torch.optim.AdamW,\n",
    "    optimizer_params=dict(lr=1e-3),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=x_train_tab.values,\n",
    "    eval_set=[x_valid_tab.values],\n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=12, \n",
    "    patience=4,\n",
    ")\n",
    "\n",
    "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=3,\n",
    "                       n_d = 8,\n",
    "                       scheduler_fn = torch.optim.lr_scheduler.StepLR,\n",
    "                       scheduler_params = {'gamma':0.9,'step_size':8},\n",
    "                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       mask_type='entmax', # \"sparsemax\",\n",
    "                       device_name='cuda',\n",
    "                      )\n",
    "\n",
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n",
    "        return score\n",
    "\n",
    "clf.fit(\n",
    "    X_train=x_train_tab.values, y_train=y_train.values.reshape(-1,),\n",
    "    eval_set=[(x_train_tab.values, y_train.values.reshape(-1,)), (x_valid_tab.values, y_valid.values.reshape(-1,))],\n",
    "    eval_name=['train', 'val'],\n",
    "    eval_metric=['logloss','f1'],\n",
    "    max_epochs=100 , patience=8,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=256,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    from_unsupervised=unsupervised_model\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost and TabNet Ensemble\n",
    "\n",
    "- 두개의 모델에서 추론한 값을 앙상블함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "C3BzOUHwNqOK",
    "outputId": "c5d15cbf-9668-4b62-ac5b-51601da285a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# threshold : 0.15, train score : 0.678, valid score : 0.676, test score : 0.676\n",
      "# threshold : 0.20, train score : 0.686, valid score : 0.682, test score : 0.682\n",
      "# threshold : 0.25, train score : 0.695, valid score : 0.687, test score : 0.688\n",
      "# threshold : 0.30, train score : 0.707, valid score : 0.693, test score : 0.694\n",
      "# threshold : 0.35, train score : 0.721, valid score : 0.697, test score : 0.699\n",
      "# threshold : 0.40, train score : 0.739, valid score : 0.698, test score : 0.702\n",
      "# threshold : 0.45, train score : 0.752, valid score : 0.690, test score : 0.694\n",
      "# threshold : 0.50, train score : 0.752, valid score : 0.663, test score : 0.668\n",
      "# threshold : 0.60, train score : 0.623, valid score : 0.489, test score : 0.490\n",
      "# threshold : 0.70, train score : 0.249, valid score : 0.156, test score : 0.154\n",
      "# threshold : 0.80, train score : 0.014, valid score : 0.005, test score : 0.006\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction for tabnet and catboost\n",
    "preds_train_tab = clf.predict_proba(x_train_tab.values)\n",
    "preds_valid_tab = clf.predict_proba(x_valid_tab.values)\n",
    "preds_test_tab = clf.predict_proba(x_test_tab.values)\n",
    "\n",
    "preds_train_cbc = cbc.predict_proba(x_train)\n",
    "preds_valid_cbc = cbc.predict_proba(x_valid)\n",
    "preds_test_cbc = cbc.predict_proba(x_test)\n",
    "\n",
    "preds_train = (preds_train_tab + preds_train_cbc) / 2\n",
    "preds_valid = (preds_valid_tab + preds_valid_cbc) / 2\n",
    "preds_test = (preds_test_tab + preds_test_cbc) / 2\n",
    "\n",
    "threshold_list = [0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.6,0.7,0.8]\n",
    "\n",
    "train_score_tab_list = []\n",
    "valid_score_tab_list = []\n",
    "test_score_tab_list = []\n",
    "\n",
    "train_score_cbc_list = []\n",
    "valid_score_cbc_list = []\n",
    "test_score_cbc_list = []\n",
    "\n",
    "train_score_ensemble_list = []\n",
    "valid_score_ensemble_list = []\n",
    "test_score_ensemble_list = []\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    preds_train_tab_binary = (preds_train_tab[:,1]>=threshold)*1\n",
    "    preds_valid_tab_binary = (preds_valid_tab[:,1]>=threshold)*1\n",
    "    preds_test_tab_binary = (preds_test_tab[:,1]>=threshold)*1\n",
    "\n",
    "    preds_train_cbc_binary = (preds_train_cbc[:,1]>=threshold)*1\n",
    "    preds_valid_cbc_binary = (preds_valid_cbc[:,1]>=threshold)*1\n",
    "    preds_test_cbc_binary = (preds_test_cbc[:,1]>=threshold)*1\n",
    "\n",
    "    train_score_tab = f1_score(y_train.values.reshape(-1,1), preds_train_tab_binary.reshape(-1,1))\n",
    "    valid_score_tab = f1_score(y_valid.values.reshape(-1,1), preds_valid_tab_binary.reshape(-1,1))\n",
    "    test_score_tab = f1_score(y_test.values.reshape(-1,1), preds_test_tab_binary.reshape(-1,1))\n",
    "\n",
    "    train_score_cbc = f1_score(y_train.values.reshape(-1,1), preds_train_cbc_binary.reshape(-1,1))\n",
    "    valid_score_cbc = f1_score(y_valid.values.reshape(-1,1), preds_valid_cbc_binary.reshape(-1,1))\n",
    "    test_score_cbc = f1_score(y_test.values.reshape(-1,1), preds_test_cbc_binary.reshape(-1,1))\n",
    "\n",
    "    train_score_tab_list.append(train_score_tab)\n",
    "    valid_score_tab_list.append(valid_score_tab)\n",
    "    test_score_tab_list.append(test_score_tab)\n",
    "\n",
    "    train_score_cbc_list.append(train_score_cbc)\n",
    "    valid_score_cbc_list.append(valid_score_cbc)\n",
    "    test_score_cbc_list.append(test_score_cbc)\n",
    "\n",
    "    preds_train_binary = (preds_train[:,1]>=threshold)*1\n",
    "    preds_valid_binary = (preds_valid[:,1]>=threshold)*1\n",
    "    preds_test_binary = (preds_test[:,1]>=threshold)*1\n",
    "\n",
    "    train_score = f1_score(y_train.values.reshape(-1,1), preds_train_binary.reshape(-1,1))\n",
    "    valid_score = f1_score(y_valid.values.reshape(-1,1), preds_valid_binary.reshape(-1,1))\n",
    "    test_score = f1_score(y_test.values.reshape(-1,1), preds_test_binary.reshape(-1,1))\n",
    "\n",
    "    print(\"# threshold : {:.2f}, train score : {:.3f}, valid score : {:.3f}, test score : {:.3f}\".format(threshold, train_score, valid_score, test_score))\n",
    "\n",
    "    train_score_ensemble_list.append(train_score)\n",
    "    valid_score_ensemble_list.append(valid_score)\n",
    "    test_score_ensemble_list.append(test_score)\n",
    "\n",
    "experiment = pd.DataFrame({\n",
    "    'threshold':threshold_list, \n",
    "    'train_score_tab':train_score_tab_list,\n",
    "    'valid_score_tab':valid_score_tab_list,\n",
    "    'test_score_tab':test_score_tab_list,\n",
    "    'train_score_cbc':train_score_cbc_list,\n",
    "    'valid_score_cbc':valid_score_cbc_list,\n",
    "    'test_score_cbc':test_score_cbc_list,\n",
    "    'train_score_ensemble':train_score_ensemble_list,\n",
    "    'valid_score_ensemble':valid_score_ensemble_list,\n",
    "    'test_score_ensemble':test_score_ensemble_list,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(experiment.threshold, experiment.train_score_ensemble, 'ro--', label =\"train score\")\n",
    "plt.plot(experiment.threshold, experiment.valid_score_ensemble, 'g*--', label =\"valid score\")\n",
    "plt.plot(experiment.threshold, experiment.test_score_ensemble, 'b.--', label =\"test score\")\n",
    "\n",
    "idx_max = np.argmax(experiment.test_score_ensemble.values)\n",
    "plt.axvline(x=experiment.threshold.values[idx_max])\n",
    "\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"f1_score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensemble 모델에서 threshold값을 주어 0과 1의 trade-off를 나타내었을 때, 0.4에서 train, valid, test의 f1 score가 가장 높은 점수를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "DiykePYpUbVs",
    "outputId": "6cd14ccf-dca0-4cb8-e986-b9f02a8866f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(experiment.threshold, experiment.test_score_tab, 'r^--', label =\"test tab score\")\n",
    "plt.plot(experiment.threshold, experiment.test_score_cbc, 'k*--', label =\"test cbc score\")\n",
    "plt.plot(experiment.threshold, experiment.test_score_ensemble, 'b.--', label =\"test ensemble score\")\n",
    "\n",
    "idx_max = np.argmax(experiment.test_score_ensemble.values)\n",
    "plt.axvline(x=experiment.threshold.values[idx_max])\n",
    "\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"f1_score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tabnet, catboost, ensemble 모델로 testset을 추론하였을때도 0.4에서 가장 높은 점수를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "3Kpi_445UyT5",
    "outputId": "7f2ab407-6bc9-4de7-ad5f-bac706f4dee8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cea21bda-5c94-4aa6-8fd2-933a5b5ec3bd\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>test_score_tab</th>\n",
       "      <th>test_score_cbc</th>\n",
       "      <th>test_score_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.674341</td>\n",
       "      <td>0.681534</td>\n",
       "      <td>0.676211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.678280</td>\n",
       "      <td>0.688719</td>\n",
       "      <td>0.682052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.681657</td>\n",
       "      <td>0.696284</td>\n",
       "      <td>0.687841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.684202</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.693619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.685224</td>\n",
       "      <td>0.708428</td>\n",
       "      <td>0.699164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.682102</td>\n",
       "      <td>0.709399</td>\n",
       "      <td>0.701527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.669205</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.694230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.636021</td>\n",
       "      <td>0.673448</td>\n",
       "      <td>0.667701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.440484</td>\n",
       "      <td>0.543804</td>\n",
       "      <td>0.490490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.125842</td>\n",
       "      <td>0.263275</td>\n",
       "      <td>0.153984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>0.005832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cea21bda-5c94-4aa6-8fd2-933a5b5ec3bd')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cea21bda-5c94-4aa6-8fd2-933a5b5ec3bd button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cea21bda-5c94-4aa6-8fd2-933a5b5ec3bd');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    threshold  test_score_tab  test_score_cbc  test_score_ensemble\n",
       "0        0.15        0.674341        0.681534             0.676211\n",
       "1        0.20        0.678280        0.688719             0.682052\n",
       "2        0.25        0.681657        0.696284             0.687841\n",
       "3        0.30        0.684202        0.703196             0.693619\n",
       "4        0.35        0.685224        0.708428             0.699164\n",
       "5        0.40        0.682102        0.709399             0.701527\n",
       "6        0.45        0.669205        0.700275             0.694230\n",
       "7        0.50        0.636021        0.673448             0.667701\n",
       "8        0.60        0.440484        0.543804             0.490490\n",
       "9        0.70        0.125842        0.263275             0.153984\n",
       "10       0.80        0.003654        0.033362             0.005832"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment[[\"threshold\",\"test_score_tab\",\"test_score_cbc\",\"test_score_ensemble\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "- testset을 추론하여 제출파일을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Vs8t4Ukfd6H"
   },
   "outputs": [],
   "source": [
    "def stacking_ensemble(df_train, df_test, num_k_fold = 4, params = None):\n",
    "\n",
    "    model_list_cbc = []\n",
    "    model_list_tab = []\n",
    "\n",
    "    threshold_list = [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.6,0.7,0.8]\n",
    "\n",
    "    x_train, y_train = df_train[x_cols].reset_index(drop = True), df_train[y_cols].reset_index(drop = True)\n",
    "    x_test, y_test = df_test[x_cols].reset_index(drop = True), df_test[y_cols].reset_index(drop = True)\n",
    "\n",
    "    x_train_tab = x_train.copy(...)\n",
    "    x_test_tab = x_test.copy(...)\n",
    "\n",
    "    # tabnet preprocessing\n",
    "    cat_idxs = []\n",
    "    cat_dims = []\n",
    "    for idx, col in enumerate(x_train_tab.columns):\n",
    "        if 'match' not in col and col!='target': # match -> boolean의 경우, 굳이 label encoder를 거칠 필요가 없다\n",
    "            le = LabelEncoder()\n",
    "            le.fit(x_train_tab[col].values)\n",
    "            le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            x_train_tab[col] = x_train_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "            x_test_tab[col] = x_test_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "            cat_idxs.append(idx)\n",
    "            cat_dims.append(len(le_dict)+1)\n",
    "\n",
    "    # catboost preprocessing\n",
    "    catboost_features = x_train.columns[x_train.nunique() > 2].tolist()\n",
    "\n",
    "    # list for training and prediction\n",
    "    preds_tab = []\n",
    "    preds_tab_test = []\n",
    "\n",
    "    preds_cbc = []\n",
    "    preds_cbc_test = []\n",
    "\n",
    "    val_idxs = []\n",
    "    k_fold = KFold(n_splits = num_k_fold, shuffle = True)\n",
    "\n",
    "    for idx, (tr_idx, val_idx) in enumerate(k_fold.split(x_train)):\n",
    "        tr_x_tab, tr_y = x_train_tab.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        val_x_tab, val_y = x_train_tab.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # TabNetPretrainer\n",
    "        unsupervised_model = TabNetPretrainer(\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            optimizer_fn=torch.optim.AdamW,\n",
    "            optimizer_params=dict(lr=1e-3),\n",
    "            mask_type='entmax' # \"sparsemax\"\n",
    "        )\n",
    "\n",
    "        unsupervised_model.fit(\n",
    "            X_train=tr_x_tab.values,\n",
    "            eval_set=[val_x_tab.values],\n",
    "            pretraining_ratio=0.8,\n",
    "            max_epochs=12, \n",
    "            patience=4,\n",
    "        )\n",
    "\n",
    "        # tabnet training\n",
    "        clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=3,\n",
    "                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
    "                       mask_type='entmax', # \"sparsemax\",\n",
    "                       scheduler_fn = torch.optim.lr_scheduler.StepLR,\n",
    "                       scheduler_params = {'gamma':0.9,'step_size':8},\n",
    "                      )\n",
    "        clf.fit(\n",
    "            X_train=tr_x_tab.values, y_train=tr_y.values.reshape(-1,),\n",
    "            eval_set=[(tr_x_tab.values, tr_y.values.reshape(-1,)), (val_x_tab.values, val_y.values.reshape(-1,))],\n",
    "            eval_name=['train', 'val'],\n",
    "            eval_metric=['logloss','f1'],\n",
    "            max_epochs=100 , patience=8,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=256,\n",
    "            num_workers=4,\n",
    "            drop_last=False,\n",
    "        ) \n",
    "\n",
    "        tr_x, tr_y = x_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        val_x, val_y = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # catboost training\n",
    "        d_train = Pool(tr_x, tr_y, feature_names = list(tr_x.columns), cat_features = catboost_features)\n",
    "        d_valid = Pool(val_x, val_y, feature_names = list(val_x.columns), cat_features = catboost_features)\n",
    "\n",
    "        cbc = CatBoostClassifier(\n",
    "            random_seed = 42,\n",
    "            task_type = 'GPU',\n",
    "            devices = '0:1',\n",
    "            custom_metric = ['Logloss','F1'],\n",
    "        )\n",
    "\n",
    "        cbc.fit(d_train, eval_set = d_valid)\n",
    "\n",
    "        # predict valid set and test set\n",
    "        pred_tab = clf.predict_proba(val_x_tab.values)[:,1].reshape(-1,)\n",
    "        pred_tab_test = clf.predict_proba(x_test_tab.values)[:,1].reshape(-1,)\n",
    "\n",
    "        pred_cbc = cbc.predict_proba(val_x.values)[:,1].reshape(-1,)\n",
    "        pred_cbc_test = cbc.predict_proba(x_test.values)[:,1].reshape(-1,)\n",
    "\n",
    "        val_idxs.append(val_idx)\n",
    "\n",
    "        preds_tab.append(pred_tab)\n",
    "        preds_tab_test.append(pred_tab_test)\n",
    "\n",
    "        preds_cbc.append(pred_cbc)\n",
    "        preds_cbc_test.append(pred_cbc_test)\n",
    "\n",
    "        model_list_tab.append(clf)\n",
    "        model_list_cbc.append(cbc)\n",
    "    \n",
    "    val_idxs = np.concatenate(val_idxs)\n",
    "    order = np.argsort(val_idxs)\n",
    "    \n",
    "    # post-processing catboost\n",
    "    preds_cbc = np.concatenate(preds_cbc, axis = 0)\n",
    "    preds_cbc = preds_cbc[order]\n",
    "    preds_cbc_test = np.mean(preds_cbc_test, axis = 0)\n",
    "\n",
    "    # post-processing tabnet \n",
    "    preds_tab = np.concatenate(preds_tab, axis = 0)\n",
    "    preds_tab = preds_tab[order]\n",
    "    preds_tab_test = np.mean(preds_tab_test, axis = 0)\n",
    "\n",
    "    # ensemble\n",
    "    preds = (preds_cbc + preds_tab) / 2   \n",
    "    preds_test = (preds_cbc_test + preds_tab_test) / 2  \n",
    "\n",
    "    threshold_select = None  \n",
    "    train_score_select = None  \n",
    "    test_score_select = None  \n",
    "\n",
    "    for threshold in threshold_list:\n",
    "        preds_binary = preds >= threshold\n",
    "        preds_test_binary = preds_test >= threshold\n",
    "\n",
    "        train_score = f1_score(y_train['target'].values.reshape(-1,1), preds_binary.reshape(-1,1))\n",
    "        test_score = f1_score(y_test['target'].values.reshape(-1,1), preds_test_binary.reshape(-1,1))\n",
    "\n",
    "        print(\"# threshold : {:.3f}, f1_score for train set : {:.3f} and test set : {:.3f}\".format(threshold, train_score, test_score))\n",
    "\n",
    "        if threshold_select is None:\n",
    "            threshold_select = threshold\n",
    "            train_score_select = train_score\n",
    "            test_score_select = test_score\n",
    "\n",
    "        if test_score_select <= test_score:\n",
    "            threshold_select = threshold\n",
    "            train_score_select = train_score\n",
    "            test_score_select = test_score\n",
    "            \n",
    "    return preds, preds_test, train_score_select, test_score_select, threshold_select, model_list_cbc, model_list_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ga6a5gAApZVH"
   },
   "outputs": [],
   "source": [
    "preds, preds_test, train_score, test_score, threshold, model_list_cbc, model_list_tab = stacking_ensemble(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    num_k_fold = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gu-AHkToGoS1",
    "outputId": "37e5fd49-7c70-4ea9-8586-54a26e50fd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 2.64159 | val_0_unsup_loss: 1.12274 |  0:00:28s\n",
      "epoch 1  | loss: 1.0396  | val_0_unsup_loss: 1.04257 |  0:00:56s\n",
      "epoch 2  | loss: 1.00965 | val_0_unsup_loss: 1.01831 |  0:01:24s\n",
      "epoch 3  | loss: 1.00106 | val_0_unsup_loss: 1.00042 |  0:01:52s\n",
      "epoch 4  | loss: 0.99494 | val_0_unsup_loss: 0.98099 |  0:02:20s\n",
      "epoch 5  | loss: 0.98607 | val_0_unsup_loss: 0.95196 |  0:02:48s\n",
      "epoch 6  | loss: 0.95795 | val_0_unsup_loss: 0.91374 |  0:03:16s\n",
      "epoch 7  | loss: 0.91536 | val_0_unsup_loss: 0.86912 |  0:03:44s\n",
      "epoch 8  | loss: 0.87373 | val_0_unsup_loss: 0.81812 |  0:04:13s\n",
      "epoch 9  | loss: 0.83258 | val_0_unsup_loss: 0.74899 |  0:04:41s\n",
      "epoch 10 | loss: 0.79201 | val_0_unsup_loss: 0.70167 |  0:05:09s\n",
      "epoch 11 | loss: 0.75808 | val_0_unsup_loss: 0.66132 |  0:05:37s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.66132\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68455 | train_logloss: 0.66917 | val_logloss: 0.67035 |  0:00:27s\n",
      "epoch 1  | loss: 0.66571 | train_logloss: 0.65638 | val_logloss: 0.65945 |  0:00:55s\n",
      "epoch 2  | loss: 0.65438 | train_logloss: 0.64497 | val_logloss: 0.65075 |  0:01:23s\n",
      "epoch 3  | loss: 0.64571 | train_logloss: 0.64038 | val_logloss: 0.64811 |  0:01:51s\n",
      "epoch 4  | loss: 0.63939 | train_logloss: 0.63037 | val_logloss: 0.64486 |  0:02:18s\n",
      "epoch 5  | loss: 0.63437 | train_logloss: 0.62504 | val_logloss: 0.64554 |  0:02:46s\n",
      "epoch 6  | loss: 0.62967 | train_logloss: 0.62129 | val_logloss: 0.64398 |  0:03:14s\n",
      "epoch 7  | loss: 0.62518 | train_logloss: 0.61514 | val_logloss: 0.64434 |  0:03:42s\n",
      "epoch 8  | loss: 0.62089 | train_logloss: 0.61081 | val_logloss: 0.64755 |  0:04:09s\n",
      "epoch 9  | loss: 0.61734 | train_logloss: 0.60486 | val_logloss: 0.64869 |  0:04:37s\n",
      "epoch 10 | loss: 0.61418 | train_logloss: 0.60163 | val_logloss: 0.65014 |  0:05:06s\n",
      "epoch 11 | loss: 0.61138 | train_logloss: 0.59896 | val_logloss: 0.64684 |  0:05:34s\n",
      "epoch 12 | loss: 0.60926 | train_logloss: 0.59472 | val_logloss: 0.65004 |  0:06:01s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 6 and best_val_logloss = 0.64398\n",
      "Best weights from best epoch are automatically used!\n",
      "time last : 106m 44s\n",
      "# process : 1 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.64604 | val_0_unsup_loss: 1.11582 |  0:00:28s\n",
      "epoch 1  | loss: 1.04014 | val_0_unsup_loss: 1.03971 |  0:00:57s\n",
      "epoch 2  | loss: 1.01037 | val_0_unsup_loss: 1.01656 |  0:01:26s\n",
      "epoch 3  | loss: 1.00178 | val_0_unsup_loss: 1.00268 |  0:01:55s\n",
      "epoch 4  | loss: 0.99623 | val_0_unsup_loss: 0.98526 |  0:02:24s\n",
      "epoch 5  | loss: 0.9885  | val_0_unsup_loss: 0.95525 |  0:02:52s\n",
      "epoch 6  | loss: 0.96323 | val_0_unsup_loss: 0.91862 |  0:03:21s\n",
      "epoch 7  | loss: 0.91916 | val_0_unsup_loss: 0.85624 |  0:03:50s\n",
      "epoch 8  | loss: 0.87617 | val_0_unsup_loss: 0.80854 |  0:04:19s\n",
      "epoch 9  | loss: 0.83094 | val_0_unsup_loss: 0.75751 |  0:04:48s\n",
      "epoch 10 | loss: 0.79274 | val_0_unsup_loss: 0.70998 |  0:05:17s\n",
      "epoch 11 | loss: 0.76217 | val_0_unsup_loss: 0.67843 |  0:05:46s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.67843\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68352 | train_logloss: 0.66536 | val_logloss: 0.66489 |  0:00:27s\n",
      "epoch 1  | loss: 0.66159 | train_logloss: 0.65307 | val_logloss: 0.65452 |  0:00:55s\n",
      "epoch 2  | loss: 0.65086 | train_logloss: 0.64267 | val_logloss: 0.64657 |  0:01:23s\n",
      "epoch 3  | loss: 0.64382 | train_logloss: 0.63512 | val_logloss: 0.64226 |  0:01:51s\n",
      "epoch 4  | loss: 0.63812 | train_logloss: 0.62918 | val_logloss: 0.6406  |  0:02:19s\n",
      "epoch 5  | loss: 0.63317 | train_logloss: 0.62232 | val_logloss: 0.63903 |  0:02:47s\n",
      "epoch 6  | loss: 0.62847 | train_logloss: 0.62131 | val_logloss: 0.64261 |  0:03:15s\n",
      "epoch 7  | loss: 0.62457 | train_logloss: 0.61197 | val_logloss: 0.64101 |  0:03:43s\n",
      "epoch 8  | loss: 0.6204  | train_logloss: 0.60894 | val_logloss: 0.64221 |  0:04:11s\n",
      "epoch 9  | loss: 0.61724 | train_logloss: 0.60467 | val_logloss: 0.64659 |  0:04:40s\n",
      "epoch 10 | loss: 0.61417 | train_logloss: 0.60082 | val_logloss: 0.64446 |  0:05:08s\n",
      "epoch 11 | loss: 0.61139 | train_logloss: 0.59663 | val_logloss: 0.64772 |  0:05:36s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 5 and best_val_logloss = 0.63903\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 2 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.67732 | val_0_unsup_loss: 1.1105  |  0:00:28s\n",
      "epoch 1  | loss: 1.04053 | val_0_unsup_loss: 1.03049 |  0:00:57s\n",
      "epoch 2  | loss: 1.01018 | val_0_unsup_loss: 1.00838 |  0:01:25s\n",
      "epoch 3  | loss: 1.00255 | val_0_unsup_loss: 0.99754 |  0:01:54s\n",
      "epoch 4  | loss: 0.99656 | val_0_unsup_loss: 0.98025 |  0:02:23s\n",
      "epoch 5  | loss: 0.98756 | val_0_unsup_loss: 0.95422 |  0:02:51s\n",
      "epoch 6  | loss: 0.96356 | val_0_unsup_loss: 0.90392 |  0:03:20s\n",
      "epoch 7  | loss: 0.92137 | val_0_unsup_loss: 0.83882 |  0:03:48s\n",
      "epoch 8  | loss: 0.87911 | val_0_unsup_loss: 0.78552 |  0:04:17s\n",
      "epoch 9  | loss: 0.83898 | val_0_unsup_loss: 0.745   |  0:04:46s\n",
      "epoch 10 | loss: 0.80906 | val_0_unsup_loss: 0.71602 |  0:05:14s\n",
      "epoch 11 | loss: 0.78259 | val_0_unsup_loss: 0.70093 |  0:05:43s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.70093\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68072 | train_logloss: 0.6628  | val_logloss: 0.66402 |  0:00:27s\n",
      "epoch 1  | loss: 0.65931 | train_logloss: 0.6501  | val_logloss: 0.65365 |  0:00:55s\n",
      "epoch 2  | loss: 0.64894 | train_logloss: 0.63949 | val_logloss: 0.64698 |  0:01:23s\n",
      "epoch 3  | loss: 0.64199 | train_logloss: 0.63478 | val_logloss: 0.64439 |  0:01:51s\n",
      "epoch 4  | loss: 0.63713 | train_logloss: 0.62829 | val_logloss: 0.64362 |  0:02:19s\n",
      "epoch 5  | loss: 0.63278 | train_logloss: 0.62207 | val_logloss: 0.64456 |  0:02:47s\n",
      "epoch 6  | loss: 0.62836 | train_logloss: 0.61736 | val_logloss: 0.64853 |  0:03:15s\n",
      "epoch 7  | loss: 0.62477 | train_logloss: 0.61426 | val_logloss: 0.64265 |  0:03:43s\n",
      "epoch 8  | loss: 0.62081 | train_logloss: 0.61091 | val_logloss: 0.64354 |  0:04:12s\n",
      "epoch 9  | loss: 0.61733 | train_logloss: 0.60573 | val_logloss: 0.64579 |  0:04:40s\n",
      "epoch 10 | loss: 0.61474 | train_logloss: 0.60392 | val_logloss: 0.64553 |  0:05:08s\n",
      "epoch 11 | loss: 0.61211 | train_logloss: 0.60083 | val_logloss: 0.6474  |  0:05:36s\n",
      "epoch 12 | loss: 0.60983 | train_logloss: 0.59587 | val_logloss: 0.65086 |  0:06:05s\n",
      "epoch 13 | loss: 0.60763 | train_logloss: 0.59373 | val_logloss: 0.65308 |  0:06:33s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 7 and best_val_logloss = 0.64265\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 3 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.65625 | val_0_unsup_loss: 1.11978 |  0:00:28s\n",
      "epoch 1  | loss: 1.04001 | val_0_unsup_loss: 1.03973 |  0:00:57s\n",
      "epoch 2  | loss: 1.00954 | val_0_unsup_loss: 1.00718 |  0:01:25s\n",
      "epoch 3  | loss: 1.0012  | val_0_unsup_loss: 0.99732 |  0:01:54s\n",
      "epoch 4  | loss: 0.99581 | val_0_unsup_loss: 0.98356 |  0:02:23s\n",
      "epoch 5  | loss: 0.98851 | val_0_unsup_loss: 0.96366 |  0:02:51s\n",
      "epoch 6  | loss: 0.97089 | val_0_unsup_loss: 0.9191  |  0:03:20s\n",
      "epoch 7  | loss: 0.92804 | val_0_unsup_loss: 0.88414 |  0:03:49s\n",
      "epoch 8  | loss: 0.8812  | val_0_unsup_loss: 0.82476 |  0:04:18s\n",
      "epoch 9  | loss: 0.84165 | val_0_unsup_loss: 0.76242 |  0:04:46s\n",
      "epoch 10 | loss: 0.80814 | val_0_unsup_loss: 0.73378 |  0:05:15s\n",
      "epoch 11 | loss: 0.77906 | val_0_unsup_loss: 0.71383 |  0:05:44s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.71383\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68441 | train_logloss: 0.66901 | val_logloss: 0.66953 |  0:00:27s\n",
      "epoch 1  | loss: 0.6642  | train_logloss: 0.65435 | val_logloss: 0.65675 |  0:00:56s\n",
      "epoch 2  | loss: 0.65261 | train_logloss: 0.64508 | val_logloss: 0.64932 |  0:01:24s\n",
      "epoch 3  | loss: 0.64409 | train_logloss: 0.63635 | val_logloss: 0.64561 |  0:01:51s\n",
      "epoch 4  | loss: 0.63818 | train_logloss: 0.62947 | val_logloss: 0.64231 |  0:02:19s\n",
      "epoch 5  | loss: 0.63386 | train_logloss: 0.62637 | val_logloss: 0.64128 |  0:02:47s\n",
      "epoch 6  | loss: 0.62941 | train_logloss: 0.6208  | val_logloss: 0.64165 |  0:03:15s\n",
      "epoch 7  | loss: 0.62551 | train_logloss: 0.61702 | val_logloss: 0.6444  |  0:03:43s\n",
      "epoch 8  | loss: 0.62071 | train_logloss: 0.60773 | val_logloss: 0.64495 |  0:04:11s\n",
      "epoch 9  | loss: 0.61745 | train_logloss: 0.606   | val_logloss: 0.64341 |  0:04:39s\n",
      "epoch 10 | loss: 0.6145  | train_logloss: 0.60126 | val_logloss: 0.64383 |  0:05:07s\n",
      "epoch 11 | loss: 0.61221 | train_logloss: 0.59957 | val_logloss: 0.64655 |  0:05:36s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 5 and best_val_logloss = 0.64128\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 4 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.63716 | val_0_unsup_loss: 1.12208 |  0:00:28s\n",
      "epoch 1  | loss: 1.03879 | val_0_unsup_loss: 1.04393 |  0:00:57s\n",
      "epoch 2  | loss: 1.01004 | val_0_unsup_loss: 1.01947 |  0:01:25s\n",
      "epoch 3  | loss: 1.00243 | val_0_unsup_loss: 1.00613 |  0:01:54s\n",
      "epoch 4  | loss: 0.99616 | val_0_unsup_loss: 0.98472 |  0:02:23s\n",
      "epoch 5  | loss: 0.98639 | val_0_unsup_loss: 0.95306 |  0:02:52s\n",
      "epoch 6  | loss: 0.95743 | val_0_unsup_loss: 0.90614 |  0:03:21s\n",
      "epoch 7  | loss: 0.91425 | val_0_unsup_loss: 0.83602 |  0:03:50s\n",
      "epoch 8  | loss: 0.87073 | val_0_unsup_loss: 0.78214 |  0:04:18s\n",
      "epoch 9  | loss: 0.83151 | val_0_unsup_loss: 0.74065 |  0:04:47s\n",
      "epoch 10 | loss: 0.80135 | val_0_unsup_loss: 0.71227 |  0:05:17s\n",
      "epoch 11 | loss: 0.77376 | val_0_unsup_loss: 0.68586 |  0:05:46s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.68586\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68106 | train_logloss: 0.66706 | val_logloss: 0.66679 |  0:00:27s\n",
      "epoch 1  | loss: 0.66348 | train_logloss: 0.65453 | val_logloss: 0.65626 |  0:00:55s\n",
      "epoch 2  | loss: 0.65185 | train_logloss: 0.64325 | val_logloss: 0.64851 |  0:01:24s\n",
      "epoch 3  | loss: 0.64367 | train_logloss: 0.63597 | val_logloss: 0.64483 |  0:01:52s\n",
      "epoch 4  | loss: 0.63737 | train_logloss: 0.63073 | val_logloss: 0.64165 |  0:02:21s\n",
      "epoch 5  | loss: 0.63276 | train_logloss: 0.62394 | val_logloss: 0.64131 |  0:02:49s\n",
      "epoch 6  | loss: 0.62849 | train_logloss: 0.62008 | val_logloss: 0.64135 |  0:03:17s\n",
      "epoch 7  | loss: 0.62471 | train_logloss: 0.61283 | val_logloss: 0.64273 |  0:03:45s\n",
      "epoch 8  | loss: 0.6204  | train_logloss: 0.60751 | val_logloss: 0.64383 |  0:04:13s\n",
      "epoch 9  | loss: 0.61715 | train_logloss: 0.60359 | val_logloss: 0.64546 |  0:04:41s\n",
      "epoch 10 | loss: 0.61412 | train_logloss: 0.60022 | val_logloss: 0.64709 |  0:05:09s\n",
      "epoch 11 | loss: 0.6113  | train_logloss: 0.60005 | val_logloss: 0.64612 |  0:05:37s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 5 and best_val_logloss = 0.64131\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 5 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.64764 | val_0_unsup_loss: 1.11322 |  0:00:28s\n",
      "epoch 1  | loss: 1.04104 | val_0_unsup_loss: 1.03793 |  0:00:57s\n",
      "epoch 2  | loss: 1.01007 | val_0_unsup_loss: 1.00743 |  0:01:25s\n",
      "epoch 3  | loss: 1.00097 | val_0_unsup_loss: 0.99592 |  0:01:54s\n",
      "epoch 4  | loss: 0.99474 | val_0_unsup_loss: 0.97789 |  0:02:23s\n",
      "epoch 5  | loss: 0.98586 | val_0_unsup_loss: 0.94938 |  0:02:52s\n",
      "epoch 6  | loss: 0.95678 | val_0_unsup_loss: 0.91242 |  0:03:21s\n",
      "epoch 7  | loss: 0.91209 | val_0_unsup_loss: 0.85071 |  0:03:50s\n",
      "epoch 8  | loss: 0.86969 | val_0_unsup_loss: 0.78849 |  0:04:18s\n",
      "epoch 9  | loss: 0.82618 | val_0_unsup_loss: 0.73287 |  0:04:47s\n",
      "epoch 10 | loss: 0.79074 | val_0_unsup_loss: 0.72021 |  0:05:16s\n",
      "epoch 11 | loss: 0.76307 | val_0_unsup_loss: 0.67673 |  0:05:45s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.67673\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68603 | train_logloss: 0.66831 | val_logloss: 0.67096 |  0:00:28s\n",
      "epoch 1  | loss: 0.66337 | train_logloss: 0.6537  | val_logloss: 0.65774 |  0:00:56s\n",
      "epoch 2  | loss: 0.65162 | train_logloss: 0.64363 | val_logloss: 0.64963 |  0:01:25s\n",
      "epoch 3  | loss: 0.64371 | train_logloss: 0.63616 | val_logloss: 0.64526 |  0:01:53s\n",
      "epoch 4  | loss: 0.63798 | train_logloss: 0.62918 | val_logloss: 0.64275 |  0:02:22s\n",
      "epoch 5  | loss: 0.63336 | train_logloss: 0.62642 | val_logloss: 0.64194 |  0:02:50s\n",
      "epoch 6  | loss: 0.62924 | train_logloss: 0.61836 | val_logloss: 0.64264 |  0:03:19s\n",
      "epoch 7  | loss: 0.62556 | train_logloss: 0.61335 | val_logloss: 0.64175 |  0:03:47s\n",
      "epoch 8  | loss: 0.62081 | train_logloss: 0.61123 | val_logloss: 0.64182 |  0:04:16s\n",
      "epoch 9  | loss: 0.61736 | train_logloss: 0.60484 | val_logloss: 0.64343 |  0:04:44s\n",
      "epoch 10 | loss: 0.6148  | train_logloss: 0.60069 | val_logloss: 0.64623 |  0:05:12s\n",
      "epoch 11 | loss: 0.6122  | train_logloss: 0.60302 | val_logloss: 0.64394 |  0:05:41s\n",
      "epoch 12 | loss: 0.60996 | train_logloss: 0.59591 | val_logloss: 0.64829 |  0:06:09s\n",
      "epoch 13 | loss: 0.60746 | train_logloss: 0.59286 | val_logloss: 0.64827 |  0:06:37s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 7 and best_val_logloss = 0.64175\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 6 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.65911 | val_0_unsup_loss: 1.12295 |  0:00:28s\n",
      "epoch 1  | loss: 1.04023 | val_0_unsup_loss: 1.04    |  0:00:57s\n",
      "epoch 2  | loss: 1.00954 | val_0_unsup_loss: 1.01635 |  0:01:25s\n",
      "epoch 3  | loss: 1.00156 | val_0_unsup_loss: 1.0029  |  0:01:54s\n",
      "epoch 4  | loss: 0.99548 | val_0_unsup_loss: 0.98175 |  0:02:23s\n",
      "epoch 5  | loss: 0.98845 | val_0_unsup_loss: 0.96044 |  0:02:52s\n",
      "epoch 6  | loss: 0.97013 | val_0_unsup_loss: 0.9248  |  0:03:21s\n",
      "epoch 7  | loss: 0.92869 | val_0_unsup_loss: 0.89137 |  0:03:50s\n",
      "epoch 8  | loss: 0.8829  | val_0_unsup_loss: 0.83869 |  0:04:19s\n",
      "epoch 9  | loss: 0.83641 | val_0_unsup_loss: 0.7517  |  0:04:48s\n",
      "epoch 10 | loss: 0.80136 | val_0_unsup_loss: 0.71625 |  0:05:17s\n",
      "epoch 11 | loss: 0.77102 | val_0_unsup_loss: 0.69596 |  0:05:46s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.69596\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68467 | train_logloss: 0.66972 | val_logloss: 0.67143 |  0:00:28s\n",
      "epoch 1  | loss: 0.66425 | train_logloss: 0.65413 | val_logloss: 0.65765 |  0:00:57s\n",
      "epoch 2  | loss: 0.65204 | train_logloss: 0.64291 | val_logloss: 0.64902 |  0:01:26s\n",
      "epoch 3  | loss: 0.64407 | train_logloss: 0.63538 | val_logloss: 0.64514 |  0:01:55s\n",
      "epoch 4  | loss: 0.63825 | train_logloss: 0.62992 | val_logloss: 0.64452 |  0:02:24s\n",
      "epoch 5  | loss: 0.63308 | train_logloss: 0.62358 | val_logloss: 0.64321 |  0:02:53s\n",
      "epoch 6  | loss: 0.62869 | train_logloss: 0.61666 | val_logloss: 0.64242 |  0:03:22s\n",
      "epoch 7  | loss: 0.62412 | train_logloss: 0.61297 | val_logloss: 0.64546 |  0:03:51s\n",
      "epoch 8  | loss: 0.6203  | train_logloss: 0.60812 | val_logloss: 0.6445  |  0:04:19s\n",
      "epoch 9  | loss: 0.61624 | train_logloss: 0.60273 | val_logloss: 0.64793 |  0:04:48s\n",
      "epoch 10 | loss: 0.61292 | train_logloss: 0.59836 | val_logloss: 0.65055 |  0:05:17s\n",
      "epoch 11 | loss: 0.61057 | train_logloss: 0.59564 | val_logloss: 0.65294 |  0:05:46s\n",
      "epoch 12 | loss: 0.60796 | train_logloss: 0.59425 | val_logloss: 0.65053 |  0:06:15s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 6 and best_val_logloss = 0.64242\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 7 / 8 complete...\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 2.6517  | val_0_unsup_loss: 1.10886 |  0:00:28s\n",
      "epoch 1  | loss: 1.03957 | val_0_unsup_loss: 1.02935 |  0:00:57s\n",
      "epoch 2  | loss: 1.00968 | val_0_unsup_loss: 1.00926 |  0:01:26s\n",
      "epoch 3  | loss: 1.00197 | val_0_unsup_loss: 0.99986 |  0:01:55s\n",
      "epoch 4  | loss: 0.9961  | val_0_unsup_loss: 0.98087 |  0:02:24s\n",
      "epoch 5  | loss: 0.98451 | val_0_unsup_loss: 0.94923 |  0:02:54s\n",
      "epoch 6  | loss: 0.95895 | val_0_unsup_loss: 0.90905 |  0:03:23s\n",
      "epoch 7  | loss: 0.91629 | val_0_unsup_loss: 0.85566 |  0:03:52s\n",
      "epoch 8  | loss: 0.87073 | val_0_unsup_loss: 0.78253 |  0:04:21s\n",
      "epoch 9  | loss: 0.83492 | val_0_unsup_loss: 0.75044 |  0:04:50s\n",
      "epoch 10 | loss: 0.80628 | val_0_unsup_loss: 0.7191  |  0:05:19s\n",
      "epoch 11 | loss: 0.7791  | val_0_unsup_loss: 0.68831 |  0:05:48s\n",
      "Stop training because you reached max_epochs = 12 with best_epoch = 11 and best_val_0_unsup_loss = 0.68831\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.68238 | train_logloss: 0.66526 | val_logloss: 0.6653  |  0:00:29s\n",
      "epoch 1  | loss: 0.66073 | train_logloss: 0.65168 | val_logloss: 0.65409 |  0:00:57s\n",
      "epoch 2  | loss: 0.65093 | train_logloss: 0.64409 | val_logloss: 0.65008 |  0:01:27s\n",
      "epoch 3  | loss: 0.64454 | train_logloss: 0.63839 | val_logloss: 0.64611 |  0:01:57s\n",
      "epoch 4  | loss: 0.63919 | train_logloss: 0.62897 | val_logloss: 0.64118 |  0:02:27s\n",
      "epoch 5  | loss: 0.63455 | train_logloss: 0.62487 | val_logloss: 0.64208 |  0:02:56s\n",
      "epoch 6  | loss: 0.63043 | train_logloss: 0.62132 | val_logloss: 0.64118 |  0:03:25s\n",
      "epoch 7  | loss: 0.6269  | train_logloss: 0.6162  | val_logloss: 0.64175 |  0:03:55s\n",
      "epoch 8  | loss: 0.62279 | train_logloss: 0.61408 | val_logloss: 0.64423 |  0:04:24s\n",
      "epoch 9  | loss: 0.61959 | train_logloss: 0.60669 | val_logloss: 0.643   |  0:04:54s\n",
      "epoch 10 | loss: 0.61661 | train_logloss: 0.60396 | val_logloss: 0.64404 |  0:05:24s\n",
      "epoch 11 | loss: 0.61385 | train_logloss: 0.60022 | val_logloss: 0.64814 |  0:05:53s\n",
      "epoch 12 | loss: 0.6112  | train_logloss: 0.59894 | val_logloss: 0.64783 |  0:06:23s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 6 and best_val_logloss = 0.64118\n",
      "Best weights from best epoch are automatically used!\n",
      "# process : 8 / 8 complete...\n",
      "# threshold : 0.100, f1_score for train set : 0.674\n",
      "# threshold : 0.150, f1_score for train set : 0.680\n",
      "# threshold : 0.200, f1_score for train set : 0.686\n",
      "# threshold : 0.250, f1_score for train set : 0.693\n",
      "# threshold : 0.300, f1_score for train set : 0.699\n",
      "# threshold : 0.350, f1_score for train set : 0.705\n",
      "# threshold : 0.400, f1_score for train set : 0.706\n",
      "# threshold : 0.450, f1_score for train set : 0.699\n",
      "# threshold : 0.500, f1_score for train set : 0.675\n",
      "# threshold : 0.600, f1_score for train set : 0.535\n",
      "# threshold : 0.700, f1_score for train set : 0.236\n",
      "# threshold : 0.800, f1_score for train set : 0.013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# submission\n",
    "df_submission = test_csv.copy(...)\n",
    "\n",
    "for bool_col in bool_cols:\n",
    "    df_submission[bool_col] = df_submission[bool_col].apply(lambda x : int(x)).astype('int64')\n",
    "\n",
    "df_submission = preprocess_data(df_submission, cols_merge, cols_equi, cols_drop)\n",
    "x_submission = df_submission[x_cols]\n",
    "\n",
    "def stacking_ensemble_submission(df, df_submission, num_k_fold = 4):\n",
    "\n",
    "    model_list_cbc = []\n",
    "    model_list_tab = []\n",
    "    threshold_list = [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.6,0.7,0.8]\n",
    "\n",
    "    x_train, y_train = df[x_cols].reset_index(drop = True), df[y_cols].reset_index(drop = True)\n",
    "    x_submission = df_submission[x_cols]\n",
    "\n",
    "    x_train_tab = x_train.copy(...)\n",
    "    x_submission_tab = x_submission.copy(...)\n",
    "\n",
    "    cat_idxs = []\n",
    "    cat_dims = []\n",
    "    for idx, col in enumerate(x_train_tab.columns):\n",
    "        if 'match' not in col and col!='target': \n",
    "            le = LabelEncoder()\n",
    "            le.fit(x_train_tab[col].values)\n",
    "            le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            x_train_tab[col] = x_train_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "            x_submission_tab[col] = x_submission_tab[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "            cat_idxs.append(idx)\n",
    "            cat_dims.append(len(le_dict)+1)\n",
    "\n",
    "    # catboost preprocessing\n",
    "    catboost_features = x_train.columns[x_train.nunique() > 2].tolist()\n",
    "\n",
    "    # list for training and prediction\n",
    "    preds_tab = []\n",
    "    preds_tab_sub = []\n",
    "\n",
    "    preds_cbc = []\n",
    "    preds_cbc_sub = []\n",
    "\n",
    "    val_idxs = []\n",
    "\n",
    "    k_fold = KFold(n_splits = num_k_fold, shuffle = True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    end_time = None\n",
    "\n",
    "    for idx, (tr_idx, val_idx) in enumerate(k_fold.split(x_train)):\n",
    "\n",
    "        tr_x_tab, tr_y = x_train_tab.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        val_x_tab, val_y = x_train_tab.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # TabNetPretrainer\n",
    "        unsupervised_model = TabNetPretrainer(\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            optimizer_fn=torch.optim.AdamW,\n",
    "            optimizer_params=dict(lr=1e-3),\n",
    "            mask_type='entmax' # \"sparsemax\"\n",
    "        )\n",
    "\n",
    "        unsupervised_model.fit(\n",
    "            X_train=tr_x_tab.values,\n",
    "            eval_set=[val_x_tab.values],\n",
    "            pretraining_ratio=0.8,\n",
    "            max_epochs=12, \n",
    "            patience=4,\n",
    "        )\n",
    "\n",
    "        # tabnet training\n",
    "        clf = TabNetClassifier(\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            cat_emb_dim=3,\n",
    "            optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
    "            mask_type='entmax', # \"sparsemax\",\n",
    "            scheduler_fn = torch.optim.lr_scheduler.StepLR,\n",
    "            scheduler_params = {'gamma':0.95,'step_size':8},\n",
    "        )\n",
    "        \n",
    "        clf.fit(\n",
    "            X_train=tr_x_tab.values, y_train=tr_y.values.reshape(-1,),\n",
    "            eval_set=[(tr_x_tab.values, tr_y.values.reshape(-1,)), (val_x_tab.values, val_y.values.reshape(-1,))],\n",
    "            eval_name=['train', 'val'],\n",
    "            eval_metric=['logloss'],\n",
    "            max_epochs=32 , patience=6,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=256,\n",
    "            num_workers=4,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        tr_x, tr_y = x_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
    "        val_x, val_y = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # catboost training\n",
    "        d_train = Pool(tr_x, tr_y, feature_names = list(tr_x.columns), cat_features = catboost_features)\n",
    "        d_valid = Pool(val_x, val_y, feature_names = list(val_x.columns), cat_features = catboost_features)\n",
    "\n",
    "        cbc = CatBoostClassifier(\n",
    "            random_seed = 42,\n",
    "            task_type = 'GPU',\n",
    "            devices = '0:1',\n",
    "            custom_metric = ['Logloss','F1'],\n",
    "        )\n",
    "\n",
    "        cbc.fit(d_train, eval_set = d_valid, verbose = False)\n",
    "\n",
    "        # predict valid set and test set\n",
    "        pred_tab = clf.predict_proba(val_x_tab.values)[:,1].reshape(-1,)\n",
    "        pred_tab_sub = clf.predict_proba(x_submission_tab.values)[:,1].reshape(-1,)\n",
    "\n",
    "        pred_cbc = cbc.predict_proba(val_x.values)[:,1].reshape(-1,)\n",
    "        pred_cbc_sub = cbc.predict_proba(x_submission.values)[:,1].reshape(-1,)\n",
    "\n",
    "        val_idxs.append(val_idx)\n",
    "\n",
    "        preds_tab.append(pred_tab)\n",
    "        preds_tab_sub.append(pred_tab_sub)\n",
    "\n",
    "        preds_cbc.append(pred_cbc)\n",
    "        preds_cbc_sub.append(pred_cbc_sub)\n",
    "\n",
    "        model_list_tab.append(clf)\n",
    "        model_list_cbc.append(cbc)\n",
    "\n",
    "        if end_time is None:\n",
    "            end_time = time.time()\n",
    "            dt = end_time - start_time\n",
    "            m = int(dt * (num_k_fold - 1) // 60 )\n",
    "            s = int(dt * (num_k_fold - 1) % 60 )\n",
    "            print(\"time last : {:2d}m {:2d}s\".format(m,s))\n",
    "        print(\"# process : {:d} / {:d} complete...\".format(idx+1, num_k_fold))\n",
    "\n",
    "    val_idxs = np.concatenate(val_idxs)\n",
    "    order = np.argsort(val_idxs)\n",
    "    \n",
    "    # post-processing catboost\n",
    "    preds_cbc = np.concatenate(preds_cbc, axis = 0)\n",
    "    preds_cbc = preds_cbc[order]\n",
    "    preds_cbc_sub = np.mean(preds_cbc_sub, axis = 0)\n",
    "\n",
    "    # post-processing tabnet \n",
    "    preds_tab = np.concatenate(preds_tab, axis = 0)\n",
    "    preds_tab = preds_tab[order]\n",
    "    preds_tab_sub = np.mean(preds_tab_sub, axis = 0)\n",
    "\n",
    "    # ensemble\n",
    "    preds = (preds_cbc + preds_tab) / 2   \n",
    "    preds_sub = (preds_cbc_sub + preds_tab_sub) / 2  \n",
    "\n",
    "    threshold_select = None  \n",
    "    train_score_select = None  \n",
    "\n",
    "    for threshold in threshold_list:\n",
    "        preds_binary = preds >= threshold\n",
    "        preds_sub_binary = preds_sub >= threshold\n",
    "\n",
    "        train_score = f1_score(y_train['target'].values.reshape(-1,1), preds_binary.reshape(-1,1))\n",
    "\n",
    "        print(\"# threshold : {:.3f}, f1_score for train set : {:.3f}\".format(threshold, train_score))\n",
    "\n",
    "        if threshold_select is None:\n",
    "            threshold_select = threshold\n",
    "            train_score_select = train_score\n",
    "\n",
    "        if train_score >= train_score_select:\n",
    "            threshold_select = threshold\n",
    "            train_score_select = train_score\n",
    "           \n",
    "    result = {\n",
    "        \"preds_cbc\" : preds_cbc,\n",
    "        \"preds_tab\" : preds_tab,\n",
    "        \"preds\" : preds,\n",
    "        \"target_train\":y_train,\n",
    "        \"preds_cbc_sub\" : preds_cbc_sub,\n",
    "        \"preds_tab_sub\" : preds_tab_sub,\n",
    "        \"preds_sub\" : preds_sub,\n",
    "        \"threshold\":threshold_select,\n",
    "        \"train_score_select\":train_score_select\n",
    "    }\n",
    "\n",
    "    return result, model_list_cbc, model_list_tab\n",
    "\n",
    "result, model_list_cbc, model_list_tab = stacking_ensemble_submission(df_preprocessed, df_submission, num_k_fold = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUw9_idVZB8U"
   },
   "outputs": [],
   "source": [
    "preds_tab = result['preds_tab']\n",
    "preds_cbc = result['preds_cbc']\n",
    "y_train = result['target_train']\n",
    "\n",
    "weights = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "threshold_list = [0.1,0.15,0.2,0.25,0.3, 0.325, 0.35, 0.375, 0.4, 0.425, 0.45,0.5,0.6,0.7,0.8]\n",
    "\n",
    "data_col_weight = []\n",
    "data_col_threshold = []\n",
    "data_col_score = []\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    for weight in weights:\n",
    "        preds_ws = weight * preds_tab + (1-weight) * preds_cbc\n",
    "        preds_ws_binary = preds_ws >= threshold\n",
    "        score = f1_score(y_train['target'].values.reshape(-1,1), preds_ws_binary.reshape(-1,1))\n",
    "\n",
    "        data_col_weight.append(weight)\n",
    "        data_col_threshold.append(threshold)\n",
    "        data_col_score.append(score)\n",
    "\n",
    "df_summary = pd.DataFrame({\"weight\":data_col_weight, \"threshold\":data_col_threshold, \"score\":data_col_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "dP18_Y1Y7gO1",
    "outputId": "f88e4e0c-d1c5-4d49-9f05-334383268349"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-acc977e5-fe44-427f-a83a-f82a6dda13b6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>threshold</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.702313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.700160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.704850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.702428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.706151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.703414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.700710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.705943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.703157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.703874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.700884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acc977e5-fe44-427f-a83a-f82a6dda13b6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-acc977e5-fe44-427f-a83a-f82a6dda13b6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-acc977e5-fe44-427f-a83a-f82a6dda13b6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    weight  threshold     score\n",
       "25     0.5      0.325  0.702313\n",
       "26     0.6      0.325  0.700160\n",
       "30     0.5      0.350  0.704850\n",
       "31     0.6      0.350  0.702428\n",
       "35     0.5      0.375  0.706151\n",
       "36     0.6      0.375  0.703414\n",
       "37     0.7      0.375  0.700710\n",
       "40     0.5      0.400  0.705943\n",
       "41     0.6      0.400  0.703157\n",
       "45     0.5      0.425  0.703874\n",
       "46     0.6      0.425  0.700884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[df_summary['score'] >= 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjGy2kbqbn0Z",
    "outputId": "c2a0948d-aca8-41dd-a103-6f621adcdefa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight       0.500000\n",
       "threshold    0.375000\n",
       "score        0.706151\n",
       "Name: 35, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_idx = np.argmax(df_summary.score.values)\n",
    "df_summary.iloc[argmax_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Cm3J0zz4XmG"
   },
   "outputs": [],
   "source": [
    "weight = 0.5\n",
    "threshold = 0.375\n",
    "preds_sub = weight * result['preds_tab_sub'] + (1-weight) * result['preds_cbc_sub']\n",
    "preds_sub_binary = preds_sub >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "q35ArAwCOiGw",
    "outputId": "6c027581-adca-4a55-8d31-bfa6cf195d25"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_327856c4-0c86-497a-a4b4-13df0bc473b6\", \"submission_0102_tab_cbc.csv\", 360132)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission[\"target\"] = np.array([int(x) for x in preds_sub_binary])\n",
    "\n",
    "# submission \n",
    "from google.colab import files\n",
    "sample_submission.to_csv(\"submission_0102_tab_cbc.csv\", index = False)\n",
    "files.download(\"submission_0102_tab_cbc.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "tabnet-catboost-ensemble-dataset2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
